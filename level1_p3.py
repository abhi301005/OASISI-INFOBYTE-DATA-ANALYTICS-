# -*- coding: utf-8 -*-
"""LEVEL1 P3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QEhtU_E9SpltlVbc8Kws-nrJPPKKjXd0

## **IMPORTING THE LIBRARIES**
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings("ignore")

"""// The first step is to import the librarys for data analysis.
numpy is for numerical operations,pandas is for data manipulation and analysis,warning is a built in function it manages warnings while execution,seaborn is for data visualization.

## **MOUNT THE GOOGLE DRIVE**
"""

from google.colab import drive
import os

drive.mount('/content/drive')

"""## **IMPORTING THE DATASET**"""

df=pd.read_csv('/content/drive/My Drive/AB_NYC_2019.csv')

"""// 'df' is a variable,pd is to read the data from the spacified file,read_csv() it is a function from pandas,/content/drive/My Drive/retail_sales_dataset.csv. it is the path to access the file."""

df.head()

"""// I used .head() to show the first 5 rows of data present in the file."""

df.tail()

"""// I used .tail() to show the last 5 rows of data present in the file it works same like .head().

## **DISCRIBING THE DATASET**
"""

df.info()

"""// .info() is used to provide column details and the type of data is used and also the memory storage."""

df.shape

"""// .shape is used for knowing how many rows and columns are present."""

df.describe()

"""// .describe is used to COUNT the data values inculuding the mean, median, mode, standard deviation."""

df.columns

"""// .columns is used to know the names of field names or columns names."""

numeric_df = df.select_dtypes(include=np.number)
numeric_df.corr()

"""// This is used to know he pairwise correlation of columns in the DataFrame

## **CHECKING THE DATA WHETHER THERE ARE ANY NULL VALUES IN THE FILE**
"""

df.isnull().sum()

"""// .isnull() is check wether there are any null values present in the file if we use .sum() we can see the how many values are null.

## **CHECKING THE UNIQUE VALUES**
"""

df.nunique()

"""//  .nunique is used for find how many unique values are present inside the every column.

## **CATEGORICAL AND NONCATEGORICAL FORM**
"""

categorical_cols = df.select_dtypes(include=['object', 'category']).columns
non_categorical_cols = df.select_dtypes(include=np.number).columns
print("Categorical Columns:", categorical_cols.tolist())
print("Non-Categorical Columns:", non_categorical_cols.tolist())

"""//   Separate the columns with the help of categorical_cols.tolist() and non_categorical_cols.tolist().

## **HANDLING MISSING DATA**
"""

df['name'].fillna('Absent', inplace = True)
df['host_name'].fillna('Absent', inplace =  True)

df = df.drop(['last_review','reviews_per_month'], axis =1)
df.isnull().sum()

"""//    In the above code we used .isnull().sum() and removing null values."""

host_areas = df.groupby(['host_name','neighbourhood_group'])['calculated_host_listings_count'].max().reset_index()
top_hosts = host_areas.sort_values(by = ['calculated_host_listings_count'], ascending = False).head(5)
top_hosts

"""//  In the above code we can say that Sonder(NYC) has more number of host listing."""

host_name = top_hosts['host_name']
host_lisitng = top_hosts['calculated_host_listings_count']
plt.bar(host_name,host_lisitng)
plt.title('Hosts with most listings in NYC',{'fontsize':18})
plt.xlabel('Host Names',{'fontsize':18})
plt.ylabel('Number of host listings',{'fontsize':18})
plt.show()

"""//  By using the bar graph we are representing the host listing details and the Host name."""

data =df.groupby(['neighbourhood_group'])['id'].count().reset_index().rename(columns = {'id':'count'}).sort_values(by='count', ascending = False)
data.head()

"""//   This code calculates the number of listings in each neighborhood group, sorts them in descending order, and then displays the top results."""

ax = sns.barplot(x = data['neighbourhood_group'], y = data['count'], data = data)
ax.set_xlabel('Neighbourhood Group')
ax.set_ylabel('Number of listings')
ax.set_title('Number of listings in each neighbourhood group')
plt.show()

"""//   Representing the neighbouring groups in a bar gaph for better understanding."""

areas_reviews = df.groupby(['neighbourhood_group'])['number_of_reviews'].max().reset_index().sort_values(by = 'number_of_reviews', ascending = False)
areas_reviews

"""//  In the above code we are checking how many reviews are given for the grops."""

reviews = areas_reviews['number_of_reviews']
plt.pie(reviews, labels = areas_reviews['neighbourhood_group'], autopct ='%0.2f%%', startangle =90, explode = [0.1,0.1,0.1,0.1,0.1], shadow = True )
plt.title('Number of reviews in each neighbourhood group', {'fontsize': 14})
plt.show()

"""//  Representing in the pie chart for better understanding the gropus iin percentage formate."""

filtered_df = df[(df['price'] < 270) & (df['price'] > 49)]
display(filtered_df.describe())

"""//  After filtering the data then we can check the data by using .describe()"""

filtered_df.agg({'price':['mean','median','max','count']})

"""//  Checking the filtered data by using aggrigate function.

## **REPRESENTATION OF BOXPLOT**
"""

plt.figure(figsize=(10,5))
ax = sns.boxplot(y='price', data=df).set_title('Price Distribution by neighbourhood group')
sns.set_theme(style='white')
plt.xlabel('Neighbourhood')
plt.ylabel('Price')
plt.show()

q_low = df['price'].quantile(0.10)
q_low

"""//  This code calculates the 10th percentile of the 'price' column in the DataFrame df and stores it in the variable q_low. This value can be used as a lower limit to filter out low prices."""

q_high = df['price'].quantile(0.90)
df_filtered_price = df[(df['price'] > q_low) & (df['price'] < q_high)]
plt.figure(figsize=(10,5))
ax = sns.boxplot(y='price', data=df_filtered_price).set_title('Price Distribution')
sns.set_theme(style='white')
plt.ylabel('Price')
plt.show()

"""//  This code filters the DataFrame based on the price column to remove outliers and then creates a box plot of the filtered price distribution."""

plt.figure(figsize=(12,8))
ax = sns.violinplot(x="neighbourhood_group", y="price", data=df).set_title('Price Distribution by neighbourhood groups')
plt.show()

"""//  This code generates a violin plot to visualize the distribution of prices across different neighborhood groups.

## **IDENTIFYING THE BUSIEST HOST**
"""

busiest_hosts = df.groupby(['host_name','host_id','room_type','neighbourhood_group'])['number_of_reviews'].max().reset_index()
busiest_hosts = busiest_hosts.sort_values(by='number_of_reviews', ascending=False).head(10)
busiest_hosts

host_name = busiest_hosts['host_name']
reviews = busiest_hosts['number_of_reviews']
plt.title('Busiest Hosts', {'fontsize':18})
plt.xlabel('Host Names',{'fontsize':13})
plt.ylabel('Number of reviews',{'fontsize':18})
plt.bar(host_name, reviews)

plt.rcParams['figure.figsize'] = (10,5)
hp = sns.histplot(df['room_type'], color= 'green')
hp.set_xlabel('Room type')
hp.set_ylabel('Number of listings')
plt.show()

"""Looking at the result above, we can clonclude that the top 5 Busiest Hosts are Ji, Carol, Asa, Wanda,Linda

## **MOST POPULAR ROOMS IN THE NEIGHBOURHOOD**
"""

se = df.groupby(['neighbourhood'])['id'].count().nlargest(10)
se

plt.figure(figsize=(12,6))
x = list(se.index)
y = list(se.values)
x.reverse()
y.reverse()

plt.title("Top 10 Neighbourhoods with the Most Listings", {'fontsize':18})
plt.ylabel("Neighbourhood", {'fontsize':18})
plt.xlabel("Total Listings", {'fontsize':18})

plt.barh(x, y)
plt.show()

"""The neighborhoods with the most listings are in Manhattan and Brooklyn which is understandable  given that tourists are more likely to stay in those areas. Williamsburg, in Brooklyn, appears first with 3,415 listings. In Manhattan, Bedford-Stuyvesant has the most listings, totaling 2,311 offers."""

df.groupby(['neighbourhood_group','neighbourhood','room_type'])['number_of_reviews'].max().reset_index().sort_values(by = 'number_of_reviews', ascending = False).head(10)

"""The most popular neighbourhood is Jamaica which is situated in Queens and the room type prefered here is Private Room."""